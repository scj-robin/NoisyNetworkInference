% !TEX root =VEMScoreEdges.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Loss function}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Log-likelihood}
\begin{align*}
 \log p(Z, G, S) 
 = & \log p(Z; \pi) + \log p(G \mid Z; \gamma) + \log p(S \mid G; \psi) \\
 = & \sum_{i, k} Z_{ik} \log \pi_k 
 + \sum_{i < j} \sum_{k, \ell} Z_{ik} Z_{j\ell} \left(G_{ij} \log \gamma_{k\ell} + (1 - G_{ij}) \log (1 - \gamma_{k\ell})\right) \\
 & + \sum_{i < j} G_{ij} \log f_1(S_{ij}) + (1 - G_{ij}) \log f_0(S_{ij})
\end{align*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Approximate distribution $q(Z, G) \approx p(Z, G \mid S)$}
\begin{equation}
q(Z, G) = q(Z) q(G \mid Z) := q(Z) p(G \mid Z, S)
\end{equation}
where
$$
p(G \mid Z, S) = \prod_{i, j} p(G_{ij} \mid Z_i, Z_j, S_{ij})
$$
and
$$
q(Z) = \prod_i q_i(Z_i) = \prod_{i, k} \tau_{ik}^{Z_{ik}}.
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Divergence $KL(q(Z, G) ; p(Z, G \mid S))$}
\begin{align*}
KL(q(Z, G) ; p(Z, G \mid S)) 
& = KL(q(Z) p(G \mid Z, S); p(Z \mid S) p(G \mid Z, S)) \\
& = KL(q(Z); p(Z \mid S)) 
+ \Esp_{q(Z)} \underset{=0}{\underbrace{KL(p(G \mid Z, S); p(G \mid Z, S))}}
\end{align*}
Still, the conditional entropy of $q(G \mid Z)$ contributes to the lower bound.


 
\paragraph{Entropy}

\begin{align}\label{eq:entropy}
\mathcal{H}(q(G,Z)) = &   \Esp_{q(Z)}[\mathcal{H}p(G| Z,Y)] + \mathcal{H}(q(Z))\\
=&  - \sum_{i,k} \tau_{ik} \log \tau_{ik}  - \sum_{ijk\ell} \tau_{ik} \tau_{j\ell}\left[\eta_{ij}^{k\ell} \log ( \eta_{ij}^{k\ell} ) +   (-1 \eta_{ij}^{k\ell}) \log(1-\eta_{ij}^{k\ell})\right]
\end{align}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{Lower bound $J(\theta, q)$}
\begin{align} \label{eq:lowerBound}
 J(\theta, q) 
 = & \log p_\theta(S) - KL(q(Z, G) ; p(Z, G \mid S)) \nonumber \\
 = & \Esp_q \log p_\theta(Z, G, S) + H(q(Z))  + \Esp_q H(q(G \mid Z)) \\ 
 = & \sum_{i, k} \tau_{ik} \log \pi_k 
%  + \sum_{i < j} \left(\etabar_{ij} \log \gamma_{k\ell} + (1 - \etabar_{ij}) \log (1 - \gamma_{k\ell})\right) \nonumber \\
 + \textcolor{red}{\sum_{i < j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \left(\eta^{k\ell}_{ij} \log \gamma_{k\ell} + (1 - \eta^{k\ell}_{ij}) \log (1 - \gamma_{k\ell})\right)} \nonumber \\
 & + \sum_{i < j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \left(\eta^{k\ell}_{ij} \log f_1(S_{ij}) + (1 - \eta^{k\ell}_{ij}) \log f_0(S_{ij})\right) \nonumber \\
 & - \sum_{i, k} \tau_{ik} \log \tau_{ik} - \sum_{i< j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \left( \eta^{k\ell}_{ij} \log \eta^{k\ell}_{ij} + (1 - \eta^{k\ell}_{ij}) \log (1 - \eta^{k\ell}_{ij}) \right)
\end{align}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Estimation equation}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\color{red}
We set
$$q_{\tau,\eta}(Z,G) = \prod_{i=1}^n \prod_{k=1}^K \tau_{ik}^{Z_{ik}} \prod_{i<j} \prod_{k,\ell} \eta_{ijk\ell}^{Z_{ik}Z_{j\ell}G_{ij}} (1- \eta_{ijk \ell})^{Z_{ik}Z_{j \ell}(1-G_{ij})}$$
where 
$\eta_{ijkl} = P_q(G_{ij}=1 | Z_i = k, Z_j = \ell)$ 
We define   
  \begin{eqnarray*}
  J(\theta,q_{\tau,\eta}) &=&  \log p_\theta(S) - KL(q_{\tau,\eta}(Z, G) ; p_\theta(Z, G \mid S)) \\
  &=&    \Esp_{q_{\tau,\eta}}[\log p_\theta(Z, G, S)]+ \Hcal(q_\tau(Z))  + \Esp_{q_\tau} \Hcal(q_\eta(G \mid Z))
  \end{eqnarray*}
  
  
  \vspace{2em}
  
Iteration $(t)$ the EM is as follows: from a current value of $\theta^{(t-1)}$

\begin{itemize}
\item \emph{(V)E-step}  $$(\tau^{(t)}, \eta^{(t)}) = \argmax_{\tau,\eta} J(\theta^{(t-1)},q_{\tau,\eta})$$
\item \emph{M-step}  $$ \theta^{(t)} = \argmax_{\theta} J(\theta,q_{\tau^{(t)}, \eta^{(t)}})$$
\end{itemize}




\color{black}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{VE step}


\color{red}
\begin{eqnarray*}
(\hat{\tau},\hat{\eta}) &=& \argmax_{\tau,\eta} J(\theta,q_{\tau,\eta}) \\
&=&  \argmin_{\tau,\eta}KL(q_{\tau,\eta}(Z, G) ; p_\theta(Z, G \mid S)) \\
&=&\argmin_{\tau,\eta} \left\{ KL(q_\tau (Z); p_\theta(Z \mid S)) 
+ \Esp_{q_\tau(Z)}  \left[KL(q_\eta(G \mid Z, S); p_\theta(G \mid Z, S))\right] \right\}
\end{eqnarray*}

\begin{itemize}
\item[$\bullet$] So from the previous equation, we have
\begin{equation}\label{eq:def_eta}
 \hat{\eta} = \argmin_{\eta} \Esp_{q_\tau(Z)}  \left[KL(q_\eta(G \mid Z, S); p_\theta(G \mid Z, S)) \right] 
 \end{equation}
 Using the independencies, we have
 
 \begin{equation}\label{eq:def_etaijkl}
 \hat{\eta}_{ij\cdot \cdot} = \argmin_{\eta_{ij \cdot \cdot}} \Esp_{q_\tau(Z)}  KL(q_\eta(G_{ij} \mid Z_{i},Z_j); p_\theta(G_{ij}  \mid Z_i,Z_j, S_{ij})) 
 \end{equation}
 $KL(q_\eta(G_{ij} \mid Z_i,Z_j); p_\theta(G_{ij} \mid Z_i,Z_j, S_{ij})) $ is minimal  ($=0$) for $$ \eta_{ijk\ell} = P_\theta(G_{ij} = 1 | Z_i=k, Z_j=l,S_{ij})  = \eta^{k\ell}_{ij}$$
Morover, for $i,j,k,l$
$$P_\theta(G_{ij} = 1 | Z_i=k , Z_j=l,S_{ij}) =  \frac{\gamma_{k\ell} f_1(S_{ij})}{\gamma_{k\ell} f_1(S_{ij}) + (1 - \gamma_{k\ell}) f_0(S_{ij})}$$

In that case $$KL(q_\eta(G \mid Z); p(G \mid Z, S)) = 0$$ and so $$\Esp_{q_\tau(Z)}\left[  KL(q_\eta(G_{ij} \mid Z_{i},Z_j, S_{ij}); p_\theta(G_{ij}  \mid Z_i,Z_j, S))\right] =0$$ (minimal)
It does not depend on $\tau$. 
\underline{So it can be done before optimizing in $\tau$}.
\item[$\bullet$] Now for fixed $\eta$ we will minimize $J(\theta,q_{\tau,\eta})$ by a fixed point equation. 
\end{itemize}

 






\color{black}


Denoting 
$$
\log A_{ijk\ell} = \eta^{k\ell}_{ij} \left(\log \gamma_{k\ell} + \log f_1(S_{ij}) -  \color{red}\log \eta^{k\ell}_{ij} \color{black}\right) + (1 - \eta^{k\ell}_{ij}) \left(\log (1 - \gamma_{k\ell}) + \log f_0(S_{ij})  -  \color{red}\log (1- \eta^{k\ell}_{ij}) \color{black}\right)  
$$

Then the lower bound is: 
$$J(\theta,\eta,\tau) =   \sum_{i, k} \tau_{ik} \log \pi_k  + 
\sum_{i < j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \log A_{ijkl} - \sum_{i, k} \tau_{ik} \log \tau_{ik}$$


setting the derivative wrt $\tau_{ik}$ to zero with the contraint $\sum_{k} \tau_{ik} = 0$ gives
$$
\log \tau_{ik} = \log \pi_k + \sum_{j, \ell} \tau_{j\ell} \log A_{ijk\ell} + \cst
\qquad \Leftrightarrow \qquad
\tau_{ik} \propto \pi_k \prod_{j, \ell} \left(A_{ijk\ell}\right)^{\tau_{j\ell}}
$$

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{M step}
Setting the derivative wrt to each parameter gives
\begin{align*}
 \widehat{\pi}_{ik} & = \sum_{i} \tau_{ik} \left/ n \right.,  
 & \widehat{\gamma}_{k\ell} & = \sum_{i < j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \eta^{k\ell}_{ij} \left/ \sum_{i < j} \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \right..
\end{align*}
Furthermore, if $f(\cdot, \psi_u) = \Ncal(\cdot, \mu_u, \sigma_u^2)$ (i.e $\psi_u = (\mu_u, \sigma_u^2)$), 
\begin{align*}
 \widehat{\mu}_0 & = \sum_{i < j} (1 - \etabar_{ij}) S_{ij} \left/ \sum_{i < j} (1 - \etabar_{ij}) \right. 
 & \widehat{\sigma}_0^2 & = \sum_{i < j} (1 - \etabar_{ij}) (S_{ij} - \widehat{\mu}_0)^2 \left/ \sum_{i < j} (1 - \etabar_{ij}) \right. \\ 
 \widehat{\mu}_1 & = \sum_{i < j} \etabar_{ij} S_{ij} \left/ \sum_{i < j} \etabar_{ij} S_{ij} \right. 
 & \widehat{\sigma}_1^2 & = \sum_{i < j} \etabar_{ij} (S_{ij} - \widehat{\mu}_0)^2 \left/ \sum_{i < j} \etabar_{ij} S_{ij} \right. \\ 
\end{align*}
The case of non-parametric version of $f_0$ and $f_1$ is considered in Apprendix \ref{sec:np}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\paragraph{By-product}
The conditional probability for an edge to be part of $G$ is denoted $\psi_{ij}^1$:
$$
\psi_{ij}^1 := \Pt\{G_{ij} = 1\} = \sum_{k, \ell} \tau_{ik} \tau_{j\ell} \eta^{k\ell}_{ij} 
$$
and we denote $\psi_{ij}^0 = 1 - \psi_{ij}^1$.



\subsection{Model selection}

Penalty for symetric networks and $d$ scores with multivariate Gaussian distirbutions. 


$$ Pen(\Mcal) = -\frac{1}{2}\left[ (K-1)\log p + \left(\frac{K(K+1)}{2} + 2 d + 2 \frac{d (d+1)}{2} \right) \log\left(\frac{p(p-1)}{2}\right)  \right]  $$ 

